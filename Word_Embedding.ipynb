{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word-Embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmBBOiav7ssi"
      },
      "source": [
        "**Word embeddings **\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to\n",
        "have a similar representation. They are a distributed representation for text that is perhaps one\n",
        "of the key breakthroughs for the impressive performance of deep learning methods on challenging\n",
        "natural language processing problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5OyI1mJ79Q9"
      },
      "source": [
        "word embedding approach for representing text is and how it differs from other\n",
        "feature extraction methods.\n",
        "\n",
        "there are 3 main algorithms for learning a word embedding from text data.\n",
        "\n",
        "1)Continuous Bag-of-Words, or CBOW model.\n",
        "\n",
        "2)Continuous Skip-Gram Model.\n",
        "\n",
        "3)matrix factorization techniques\n",
        "\n",
        "you can either train a new embedding or use a pre-trained embedding on your natural\n",
        "language processing task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3GNCXLKAhH6"
      },
      "source": [
        "The CBOW model learns the embedding by predicting the current word based on its context.\n",
        "The continuous skip-gram model learns by predicting the surrounding words given a current\n",
        "word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BWznsXS8JN1"
      },
      "source": [
        "**What Are Word Embeddings?**\n",
        "\n",
        "A word embedding is a learned representation for text where words that have the same meaning\n",
        "have a similar representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hDQgcw08MyU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qlidjp6AzID"
      },
      "source": [
        "word embedding Modees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wseirnBgA6aD"
      },
      "source": [
        "**Word2Vec**\n",
        "\n",
        "Word2Vec is a statistical method for e\u000eciently learning a standalone word embedding from a\n",
        "text corpus. It was developed by Tomas Mikolov, et al. at Google in 2013 as a response to make\n",
        "the neural-network-based training of the embedding more e\u000ecient and since then has become\n",
        "the de facto standard for developing pre-trained word embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5roDbx0rBQbj"
      },
      "source": [
        "We find that these representations are surprisingly good at capturing syntactic and\n",
        "semantic regularities in language, and that each relationship is characterized by a\n",
        "relation-specific vector offset. This allows vector-oriented reasoning based on the\n",
        "offsets between words. For example, the male/female relationship is automatically\n",
        "learned, and with the induced vector representations, King - Man + Woman results\n",
        "in a vector very close to Queen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thR-l_D8A4OS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQjJPWn6Bdgs"
      },
      "source": [
        "**GloVe**\n",
        "\n",
        "The Global Vectors for Word Representation, or GloVe, algorithm is an extension to the\n",
        "Word2Vec method for eficiently learning word vectors, developed by Pennington, et al. at\n",
        "Stanford. Classical vector space model representations of words were developed using matrix factorization techniques such as Latent Semantic Analysis (LSA) that do a good job of using\n",
        "global text statistics but are not as good as the learned methods like Word2Vec at capturing\n",
        "meaning and demonstrating it on tasks like calculating analogies (e.g. the King and Queen\n",
        "example above).\n",
        "GloVe is an approach to marry both the global statistics of matrix factorization techniques\n",
        "like LSA with the local context-based learning in Word2Vec. Rather than using a window to\n",
        "de\fne local context, GloVe constructs an explicit word-context or word co-occurrence matrix\n",
        "using statistics across the whole text corpus. The result is a learning model that may result in\n",
        "generally better word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipea4fqjBeqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNaet_HJCUHy"
      },
      "source": [
        "**Reuse an Embedding**\n",
        "\n",
        "It is common for researchers to make pre-trained word embeddings available for free, often under\n",
        "a permissive license so that you can use them on your own academic or commercial projects. For\n",
        "example, both Word2Vec and GloVe word embeddings are available for free download. These\n",
        "can be used on your project instead of training your own embeddings from scratch. You have\n",
        "two main options when it comes to using pre-trained embeddings:\n",
        "\n",
        "Static, where the embedding is kept static and is used as a component of your model.\n",
        "This is a suitable approach if the embedding is a good fit for your problem and gives good\n",
        "results.\n",
        "\n",
        "Updated, where the pre-trained embedding is used to seed the model, but the embedding\n",
        "is updated jointly during the training of the model. This may be a good option if you are\n",
        "looking to get the most out of the model and embedding on your task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2DYdEz9CXqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVFho3U8D9dV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ff4Hj-D9xB"
      },
      "source": [
        "Example of Learning an Embedding.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0wYy1rD-b0"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFMEGN4HEB2m"
      },
      "source": [
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPPRemhfED_W"
      },
      "source": [
        "### Vocabulary size\n",
        "voc_size=50"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8qMgW4EJkq",
        "outputId": "49793c62-d1bf-4b28-c10c-7bd72e42792b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
        "print(onehot_repr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35, 16, 3, 23], [35, 16, 3, 42], [35, 19, 3, 9], [42, 2, 19, 32, 17], [42, 2, 19, 32, 18], [21, 35, 34, 3, 49], [49, 14, 19, 32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX9gVDzmEWYI",
        "outputId": "35335f22-3b99-4d24-c858-35ea7052d749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "onehot_repr"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[35, 16, 3, 23],\n",
              " [35, 16, 3, 42],\n",
              " [35, 19, 3, 9],\n",
              " [42, 2, 19, 32, 17],\n",
              " [42, 2, 19, 32, 18],\n",
              " [21, 35, 34, 3, 49],\n",
              " [49, 14, 19, 32]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYsUNZMzEYjB"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb5k_6O6Esuz",
        "outputId": "b84027e9-de2d-4ab4-aa42-fe42f31e1cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "sent_length=5\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0 35 16  3 23]\n",
            " [ 0 35 16  3 42]\n",
            " [ 0 35 19  3  9]\n",
            " [42  2 19 32 17]\n",
            " [42  2 19 32 18]\n",
            " [21 35 34  3 49]\n",
            " [ 0 49 14 19 32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIB09ta8Eyai",
        "outputId": "abc2eb15-6ff5-463b-bd06-1ac03dd05388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "sent_length=5\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='post',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35 16  3 23  0]\n",
            " [35 16  3 42  0]\n",
            " [35 19  3  9  0]\n",
            " [42  2 19 32 17]\n",
            " [42  2 19 32 18]\n",
            " [21 35 34  3 49]\n",
            " [49 14 19 32  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Iho-CDE1td"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIorUVVpFp33"
      },
      "source": [
        "input_dim: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
        "\n",
        "output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
        "\n",
        "input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlLQSFqLFqdi"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,30,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGA-Vc9ZFvIZ",
        "outputId": "d44ec019-de30-4e0c-ce38-62dbde4b2edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 5, 30)             1500      \n",
            "=================================================================\n",
            "Total params: 1,500\n",
            "Trainable params: 1,500\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMRbcNGUFz5P",
        "outputId": "c4fb2857-6942-4d56-8578-c6c7cafb5390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.predict(embedded_docs))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.04107963  0.02798226  0.00504835 ... -0.01300856 -0.03860293\n",
            "   -0.02766579]\n",
            "  [-0.00481569 -0.01037474  0.04120917 ...  0.00263121 -0.02568066\n",
            "    0.01011343]\n",
            "  [ 0.00198215 -0.02069547  0.02648307 ... -0.03252503  0.02282203\n",
            "   -0.04572082]\n",
            "  [ 0.03792934 -0.00712482  0.02544123 ...  0.04123605 -0.01814964\n",
            "   -0.00654888]\n",
            "  [-0.02668467 -0.01835966 -0.03522006 ...  0.04140535  0.0189225\n",
            "   -0.04600055]]\n",
            "\n",
            " [[-0.04107963  0.02798226  0.00504835 ... -0.01300856 -0.03860293\n",
            "   -0.02766579]\n",
            "  [-0.00481569 -0.01037474  0.04120917 ...  0.00263121 -0.02568066\n",
            "    0.01011343]\n",
            "  [ 0.00198215 -0.02069547  0.02648307 ... -0.03252503  0.02282203\n",
            "   -0.04572082]\n",
            "  [ 0.01316294  0.00065475  0.03676306 ... -0.04894551 -0.00638874\n",
            "    0.04131993]\n",
            "  [-0.02668467 -0.01835966 -0.03522006 ...  0.04140535  0.0189225\n",
            "   -0.04600055]]\n",
            "\n",
            " [[-0.04107963  0.02798226  0.00504835 ... -0.01300856 -0.03860293\n",
            "   -0.02766579]\n",
            "  [ 0.0131233   0.01387981 -0.02150233 ...  0.01600361  0.0482084\n",
            "   -0.0252017 ]\n",
            "  [ 0.00198215 -0.02069547  0.02648307 ... -0.03252503  0.02282203\n",
            "   -0.04572082]\n",
            "  [-0.02954168  0.03274697 -0.01680797 ... -0.04037496 -0.02626701\n",
            "   -0.00902857]\n",
            "  [-0.02668467 -0.01835966 -0.03522006 ...  0.04140535  0.0189225\n",
            "   -0.04600055]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.01316294  0.00065475  0.03676306 ... -0.04894551 -0.00638874\n",
            "    0.04131993]\n",
            "  [ 0.00424827  0.04449776  0.02731605 ... -0.02988194  0.04692289\n",
            "    0.03105013]\n",
            "  [ 0.0131233   0.01387981 -0.02150233 ...  0.01600361  0.0482084\n",
            "   -0.0252017 ]\n",
            "  [ 0.00844182 -0.01755178 -0.04106779 ... -0.02053334  0.0315077\n",
            "   -0.0002888 ]\n",
            "  [ 0.02003412  0.03885182  0.02095908 ...  0.00430484 -0.00174678\n",
            "   -0.00486516]]\n",
            "\n",
            " [[ 0.01641553  0.02864326  0.0218836  ...  0.04934661 -0.02326236\n",
            "   -0.0397333 ]\n",
            "  [-0.04107963  0.02798226  0.00504835 ... -0.01300856 -0.03860293\n",
            "   -0.02766579]\n",
            "  [-0.02015878 -0.04354239  0.03858824 ...  0.00769164 -0.04714432\n",
            "   -0.02413975]\n",
            "  [ 0.00198215 -0.02069547  0.02648307 ... -0.03252503  0.02282203\n",
            "   -0.04572082]\n",
            "  [-0.04621563  0.04090795  0.01006088 ...  0.02493044 -0.04825971\n",
            "    0.03679205]]\n",
            "\n",
            " [[-0.04621563  0.04090795  0.01006088 ...  0.02493044 -0.04825971\n",
            "    0.03679205]\n",
            "  [ 0.03535696  0.03087076 -0.02225634 ...  0.02759639 -0.04841977\n",
            "   -0.02801362]\n",
            "  [ 0.0131233   0.01387981 -0.02150233 ...  0.01600361  0.0482084\n",
            "   -0.0252017 ]\n",
            "  [ 0.00844182 -0.01755178 -0.04106779 ... -0.02053334  0.0315077\n",
            "   -0.0002888 ]\n",
            "  [-0.02668467 -0.01835966 -0.03522006 ...  0.04140535  0.0189225\n",
            "   -0.04600055]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zz-25GjF6Pk"
      },
      "source": [
        "k=model.predict(embedded_docs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9z6h-sF9oh",
        "outputId": "2e2a82b4-8615-49be-9ee4-267b25b30530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "k.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 5, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FOcJfnF_fY",
        "outputId": "d1fa0c41-c67d-43e4-c86d-0c3426351a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embedded_docs[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35, 16,  3, 23,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh2ZrVWrGDlR",
        "outputId": "bb2ed4b2-971c-4d20-eb41-637cc9547a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "k[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03437621, -0.04484242,  0.01587452, -0.0010276 ,  0.01732356,\n",
              "         0.00340376,  0.0001472 , -0.01428288,  0.00482794, -0.02990921,\n",
              "         0.04243921,  0.00995375, -0.02060571,  0.02119625,  0.00522514,\n",
              "         0.01108086, -0.0222962 ,  0.03276416, -0.0435637 , -0.02021109],\n",
              "       [ 0.0076919 ,  0.01903603, -0.00264392,  0.03987211, -0.02075864,\n",
              "         0.01787741, -0.02374915, -0.00939726,  0.01387617, -0.04343615,\n",
              "         0.00634513, -0.02770804, -0.04302816,  0.02323948, -0.03237991,\n",
              "         0.04366989,  0.01167832, -0.01801644,  0.03282542, -0.02173652],\n",
              "       [ 0.04840187, -0.00031609,  0.00032292, -0.00491963, -0.00975794,\n",
              "         0.00951775,  0.04937495,  0.04188155, -0.00395557,  0.03028804,\n",
              "         0.01697947, -0.00046738,  0.02995516,  0.04132083,  0.00053941,\n",
              "         0.01912549, -0.02020488,  0.02088561, -0.01641457,  0.01974192],\n",
              "       [ 0.04154417,  0.04976075, -0.02040995,  0.02098817, -0.01643115,\n",
              "        -0.02558912, -0.04480329,  0.01053611,  0.01908987, -0.01911644,\n",
              "        -0.00437425,  0.02417524,  0.01029768, -0.00170546,  0.04407613,\n",
              "        -0.02787372,  0.01917726,  0.04085286, -0.01765298,  0.01855041],\n",
              "       [-0.01094424, -0.04871454, -0.02796651, -0.02426616,  0.03411135,\n",
              "        -0.04245805,  0.00729046,  0.04270197,  0.00860689,  0.04375089,\n",
              "         0.00575202, -0.0336075 ,  0.04968044, -0.03939134,  0.00831439,\n",
              "         0.02471148,  0.03268155, -0.04590858,  0.0376117 , -0.0418988 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APBskG6IGGYF",
        "outputId": "1bd3d7c9-1c9c-494d-a324-9946e37e5b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "k[0][0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04107963,  0.02798226,  0.00504835,  0.03728746, -0.03153685,\n",
              "        0.03970054, -0.04818378, -0.020865  , -0.01016577,  0.03835512,\n",
              "        0.01578159,  0.03428097,  0.01599525,  0.01716676,  0.01395203,\n",
              "       -0.02697303, -0.03869788,  0.03522957, -0.02241256,  0.03318893,\n",
              "        0.00314027,  0.02009565,  0.02629269, -0.03216336,  0.01254712,\n",
              "       -0.01182114,  0.03007689, -0.01300856, -0.03860293, -0.02766579],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biMxs5umGRN2",
        "outputId": "11c23796-1248-4916-caa3-d2582964f4ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embedded_docs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 27, 14, 20,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaa3iQyWGSty",
        "outputId": "8af9f5ae-c944-40c5-94a0-c6c76ffa46e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "k[1][0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04107963,  0.02798226,  0.00504835,  0.03728746, -0.03153685,\n",
              "        0.03970054, -0.04818378, -0.020865  , -0.01016577,  0.03835512,\n",
              "        0.01578159,  0.03428097,  0.01599525,  0.01716676,  0.01395203,\n",
              "       -0.02697303, -0.03869788,  0.03522957, -0.02241256,  0.03318893,\n",
              "        0.00314027,  0.02009565,  0.02629269, -0.03216336,  0.01254712,\n",
              "       -0.01182114,  0.03007689, -0.01300856, -0.03860293, -0.02766579],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnXQolftGCg4"
      },
      "source": [
        "a=k[0][4]\n",
        "b=k[1][4]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puLtUAsyGV_X"
      },
      "source": [
        "c=a.dot(b)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_IXAQZxGXe0"
      },
      "source": [
        "a1=np.linalg.norm(a)\n",
        "b1=np.linalg.norm(b)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMu4ZB2TGYwW"
      },
      "source": [
        "ang=c/(a1*b1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5f_TWXBGa86",
        "outputId": "3a1e0a79-9ad3-4b79-dd9a-34a8a44a73ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ang"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1gJXS_gGcjz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PYbIyOeI7mO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doEkgUZzI76x"
      },
      "source": [
        "Example of Learning an Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJuwfWy5I8bX"
      },
      "source": [
        "\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otyjrnJwI-vs",
        "outputId": "4a1b7c33-38b2-4a05-e506-15e6bc5edd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11, 15], [32, 21], [23, 26], [20, 21], [38], [30], [14, 26], [17, 32], [14, 21], [28, 32, 15, 48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhUCo2HEJAdS",
        "outputId": "1a157f24-4b32-4b1d-ba14-44f7649d6468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11 15  0  0]\n",
            " [32 21  0  0]\n",
            " [23 26  0  0]\n",
            " [20 21  0  0]\n",
            " [38  0  0  0]\n",
            " [30  0  0  0]\n",
            " [14 26  0  0]\n",
            " [17 32  0  0]\n",
            " [14 21  0  0]\n",
            " [28 32 15 48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWaK4obsJClq"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc9Ise7zJEzq",
        "outputId": "eb26bd54-6f2f-4277-a55d-2b2f9982fea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hl5iFTvJO7x",
        "outputId": "c7fa8344-6f57-4437-ce75-3b2a0e99c093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=1)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.6000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.6000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 921us/step - loss: 0.6862 - accuracy: 0.6000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.6000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 837us/step - loss: 0.6773 - accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 877us/step - loss: 0.6751 - accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 926us/step - loss: 0.6729 - accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 779us/step - loss: 0.6684 - accuracy: 0.6000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0cdd66a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj2g02mJTH7",
        "outputId": "01df844d-212c-4345-8a3e-415e0ad7d27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 69.999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PalzdSEIIOQK",
        "outputId": "972a3ce7-0092-4ae3-d098-fc8f60c70c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "padded_docs.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqmF0SPjId0I"
      },
      "source": [
        "a=padded_docs[0]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylt7iTcMIo1T",
        "outputId": "da3a8cc0-f10e-4a9d-af22-71b3b86ccfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 15,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5pQzLymIoEE",
        "outputId": "21b9c2be-4dea-416d-b545-10db49081f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brgb2R3fIuDe"
      },
      "source": [
        "a=a.reshape(1,4)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrLQTLSDIxlc",
        "outputId": "56374bdb-ea09-40d4-dd22-6503332d9d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHMZKoJaIzQl"
      },
      "source": [
        "k=model.predict(a)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jCuyJ2pI32H"
      },
      "source": [
        "k=np.where(k>.5,1,0)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH9DKWD4JABX",
        "outputId": "51aaf2c1-6cf1-4b26-9698-239caa981ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "k"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFP8DDdPJAqt"
      },
      "source": [
        "sent1=\"great Work\""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vci6vnGaJQ_6",
        "outputId": "174726f8-2634-499b-acb5-d01bcd7e940a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "onehot_repr=[one_hot(sent1,voc_size)] \n",
        "print(onehot_repr)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[23, 21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVR2doRKJfZA",
        "outputId": "7a83f9ae-8919-4929-f8eb-3684adbc84da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(onehot_repr, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[23 21  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZx9FlJ-J1a3",
        "outputId": "0c8773d2-9f9b-4ab4-a56d-29dc304f195c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "padded_docs.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j44N2SruKUXm"
      },
      "source": [
        "k=model.predict(a)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRPcFaztKaPv"
      },
      "source": [
        "k=np.where(k>.5,1,0)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZZ60-CYKdPE",
        "outputId": "370bf181-f125-44d9-b3e2-934a59bca478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "k"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gon_SqO0KfR5"
      },
      "source": [
        "sent2=\"great work but do again\""
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_VbNrFeKs47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}